{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ALTEGRAD_2021_Lab3_OUMAIMA_MARBOUH_transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "# Transfer learning for NLP\n",
        "## ALTEGRAD - Lab session 3\n",
        "#### Moussa Kamal Eddine, Hadi Abdine (Dascim LIX)\n",
        "##### 23 November 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(ntoken, nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid, dropout) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(nhid, nhead, nhid, dropout) #fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers) #fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid) \n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "    \n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout)#fill me\n",
        "        self.classifier = ClassificationHead(nhid, nclasses) #fill me \n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # base model\n",
        "        x = self.base.forward(src, src_mask) #fill me\n",
        "        # classifier model\n",
        "        output = self.classifier.forward(x)#fill me\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhb2gkUhJMR0",
        "outputId": "44b684a7-1eb7-40e2-eb51-b21ebf1cea01"
      },
      "source": [
        "ntokens = 100 #fill me # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape? -> yes (probability of the 6 tokens to follow the input 6 tokens, with 100 possible classes for each)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUnumRQQBaFl",
        "outputId": "ced4d148-cef9-4f9a-b235-e558e2b06330"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: \n",
        "            continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params += param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "count_parameters(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------+------------+\n",
            "|                           Modules                           | Parameters |\n",
            "+-------------------------------------------------------------+------------+\n",
            "|                     base.encoder.weight                     |   20000    |\n",
            "|  base.transformer_encoder.layers.0.self_attn.in_proj_weight |   120000   |\n",
            "|   base.transformer_encoder.layers.0.self_attn.in_proj_bias  |    600     |\n",
            "| base.transformer_encoder.layers.0.self_attn.out_proj.weight |   40000    |\n",
            "|  base.transformer_encoder.layers.0.self_attn.out_proj.bias  |    200     |\n",
            "|       base.transformer_encoder.layers.0.linear1.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.0.linear1.bias       |    200     |\n",
            "|       base.transformer_encoder.layers.0.linear2.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.0.linear2.bias       |    200     |\n",
            "|        base.transformer_encoder.layers.0.norm1.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.0.norm1.bias        |    200     |\n",
            "|        base.transformer_encoder.layers.0.norm2.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.0.norm2.bias        |    200     |\n",
            "|  base.transformer_encoder.layers.1.self_attn.in_proj_weight |   120000   |\n",
            "|   base.transformer_encoder.layers.1.self_attn.in_proj_bias  |    600     |\n",
            "| base.transformer_encoder.layers.1.self_attn.out_proj.weight |   40000    |\n",
            "|  base.transformer_encoder.layers.1.self_attn.out_proj.bias  |    200     |\n",
            "|       base.transformer_encoder.layers.1.linear1.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.1.linear1.bias       |    200     |\n",
            "|       base.transformer_encoder.layers.1.linear2.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.1.linear2.bias       |    200     |\n",
            "|        base.transformer_encoder.layers.1.norm1.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.1.norm1.bias        |    200     |\n",
            "|        base.transformer_encoder.layers.1.norm2.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.1.norm2.bias        |    200     |\n",
            "|  base.transformer_encoder.layers.2.self_attn.in_proj_weight |   120000   |\n",
            "|   base.transformer_encoder.layers.2.self_attn.in_proj_bias  |    600     |\n",
            "| base.transformer_encoder.layers.2.self_attn.out_proj.weight |   40000    |\n",
            "|  base.transformer_encoder.layers.2.self_attn.out_proj.bias  |    200     |\n",
            "|       base.transformer_encoder.layers.2.linear1.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.2.linear1.bias       |    200     |\n",
            "|       base.transformer_encoder.layers.2.linear2.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.2.linear2.bias       |    200     |\n",
            "|        base.transformer_encoder.layers.2.norm1.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.2.norm1.bias        |    200     |\n",
            "|        base.transformer_encoder.layers.2.norm2.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.2.norm2.bias        |    200     |\n",
            "|  base.transformer_encoder.layers.3.self_attn.in_proj_weight |   120000   |\n",
            "|   base.transformer_encoder.layers.3.self_attn.in_proj_bias  |    600     |\n",
            "| base.transformer_encoder.layers.3.self_attn.out_proj.weight |   40000    |\n",
            "|  base.transformer_encoder.layers.3.self_attn.out_proj.bias  |    200     |\n",
            "|       base.transformer_encoder.layers.3.linear1.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.3.linear1.bias       |    200     |\n",
            "|       base.transformer_encoder.layers.3.linear2.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.3.linear2.bias       |    200     |\n",
            "|        base.transformer_encoder.layers.3.norm1.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.3.norm1.bias        |    200     |\n",
            "|        base.transformer_encoder.layers.3.norm2.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.3.norm2.bias        |    200     |\n",
            "|                  classifier.decoder.weight                  |   20000    |\n",
            "|                   classifier.decoder.bias                   |    100     |\n",
            "+-------------------------------------------------------------+------------+\n",
            "Total Trainable Params: 1008100\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1008100"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qjd26ghWuff",
        "outputId": "976ebc45-d49b-418a-db20-054ace2b0029"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-11-28 23:46:21--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt’\n",
            "\n",
            "dict.txt            100%[===================>] 564.05K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-11-28 23:46:21 (11.0 MB/s) - ‘dict.txt’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFdH_-JeFbGA",
        "outputId": "b8a2ada7-6732-4c41-8a68-650372883f98"
      },
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "decay = len(token2ind)\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] = idx + decay #fill me\n",
        "\n",
        "ind2token = {ind: token for token, ind in token2ind.items()} #fill me\n",
        "\n",
        "print(ind2token[1111])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "▁trop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [self.token2ind[\"<sos>\"]] + [\n",
        "            self.token2ind[word] if word in self.token2ind else self.token2ind[\"<oov>\"]\n",
        "            for word in sequence[: self.max_len]\n",
        "        ]\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "    \n",
        "    losses = []\n",
        "    with tqdm(total=len(data_loader)) as pbar:\n",
        "        for idx, data in enumerate(data_loader): #step 1\n",
        "            optimizer.zero_grad()\n",
        "            src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "                device\n",
        "            )\n",
        "            input = data[0].to(device)\n",
        "            output = model(input, src_mask) #step 2\n",
        "            if task == 'classification':\n",
        "                #last vector only\n",
        "                output = output[-1] #fill me \n",
        "            output = output.view(-1, output.shape[-1])\n",
        "            target = data[1] #fill me\n",
        "            target = target.to(device)\n",
        "            loss = criterion(output, target) #fill me, Cross entropy check next cells\n",
        "            #fill me step 3\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient \n",
        "            #fill me step 4\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() \n",
        "            if idx % log_interval == 0 and idx > 0:\n",
        "                cur_loss = total_loss / log_interval\n",
        "                print(\n",
        "                    \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                    \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                        epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                    )\n",
        "                )\n",
        "                losses.append(cur_loss)\n",
        "                total_loss = 0\n",
        "            pbar.update(1)\n",
        "    return losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgf6BDB9jUr6",
        "outputId": "4077618a-bdad-49a9-db13-89a36b089031"
      },
      "source": [
        "ntokens = len(ind2token) #fill me # the size of vocabulary\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "count_parameters(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------+------------+\n",
            "|                           Modules                           | Parameters |\n",
            "+-------------------------------------------------------------+------------+\n",
            "|                     base.encoder.weight                     |  10000200  |\n",
            "|  base.transformer_encoder.layers.0.self_attn.in_proj_weight |   120000   |\n",
            "|   base.transformer_encoder.layers.0.self_attn.in_proj_bias  |    600     |\n",
            "| base.transformer_encoder.layers.0.self_attn.out_proj.weight |   40000    |\n",
            "|  base.transformer_encoder.layers.0.self_attn.out_proj.bias  |    200     |\n",
            "|       base.transformer_encoder.layers.0.linear1.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.0.linear1.bias       |    200     |\n",
            "|       base.transformer_encoder.layers.0.linear2.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.0.linear2.bias       |    200     |\n",
            "|        base.transformer_encoder.layers.0.norm1.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.0.norm1.bias        |    200     |\n",
            "|        base.transformer_encoder.layers.0.norm2.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.0.norm2.bias        |    200     |\n",
            "|  base.transformer_encoder.layers.1.self_attn.in_proj_weight |   120000   |\n",
            "|   base.transformer_encoder.layers.1.self_attn.in_proj_bias  |    600     |\n",
            "| base.transformer_encoder.layers.1.self_attn.out_proj.weight |   40000    |\n",
            "|  base.transformer_encoder.layers.1.self_attn.out_proj.bias  |    200     |\n",
            "|       base.transformer_encoder.layers.1.linear1.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.1.linear1.bias       |    200     |\n",
            "|       base.transformer_encoder.layers.1.linear2.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.1.linear2.bias       |    200     |\n",
            "|        base.transformer_encoder.layers.1.norm1.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.1.norm1.bias        |    200     |\n",
            "|        base.transformer_encoder.layers.1.norm2.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.1.norm2.bias        |    200     |\n",
            "|  base.transformer_encoder.layers.2.self_attn.in_proj_weight |   120000   |\n",
            "|   base.transformer_encoder.layers.2.self_attn.in_proj_bias  |    600     |\n",
            "| base.transformer_encoder.layers.2.self_attn.out_proj.weight |   40000    |\n",
            "|  base.transformer_encoder.layers.2.self_attn.out_proj.bias  |    200     |\n",
            "|       base.transformer_encoder.layers.2.linear1.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.2.linear1.bias       |    200     |\n",
            "|       base.transformer_encoder.layers.2.linear2.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.2.linear2.bias       |    200     |\n",
            "|        base.transformer_encoder.layers.2.norm1.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.2.norm1.bias        |    200     |\n",
            "|        base.transformer_encoder.layers.2.norm2.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.2.norm2.bias        |    200     |\n",
            "|  base.transformer_encoder.layers.3.self_attn.in_proj_weight |   120000   |\n",
            "|   base.transformer_encoder.layers.3.self_attn.in_proj_bias  |    600     |\n",
            "| base.transformer_encoder.layers.3.self_attn.out_proj.weight |   40000    |\n",
            "|  base.transformer_encoder.layers.3.self_attn.out_proj.bias  |    200     |\n",
            "|       base.transformer_encoder.layers.3.linear1.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.3.linear1.bias       |    200     |\n",
            "|       base.transformer_encoder.layers.3.linear2.weight      |   40000    |\n",
            "|        base.transformer_encoder.layers.3.linear2.bias       |    200     |\n",
            "|        base.transformer_encoder.layers.3.norm1.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.3.norm1.bias        |    200     |\n",
            "|        base.transformer_encoder.layers.3.norm2.weight       |    200     |\n",
            "|         base.transformer_encoder.layers.3.norm2.bias        |    200     |\n",
            "|                  classifier.decoder.weight                  |  10000200  |\n",
            "|                   classifier.decoder.bias                   |   50001    |\n",
            "+-------------------------------------------------------------+------------+\n",
            "Total Trainable Params: 21018401\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "21018401"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwh3n9xZQy4e",
        "outputId": "235e47d1-dcce-4d6c-c0ed-cef44381f5a5"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-11-28 23:46:22--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-11-28 23:46:23 (82.9 MB/s) - ‘pretraining_subset.txt’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m11g4ScjZaR",
        "outputId": "6cf84d0c-fa49-427b-ad7d-bb4f406c2e73"
      },
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\",\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 503/3125 [00:53<04:16, 10.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 7.32519 | ppl 1518.067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 1002/3125 [01:49<04:52,  7.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |  1000/ 3125 steps | loss 6.48536 | ppl  655.475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 1503/3125 [02:42<02:34, 10.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |  1500/ 3125 steps | loss 6.19757 | ppl  491.555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 2002/3125 [03:38<01:51, 10.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |  2000/ 3125 steps | loss 6.03485 | ppl  417.737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 2502/3125 [04:32<01:00, 10.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |  2500/ 3125 steps | loss 5.92491 | ppl  374.247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 3002/3125 [05:30<00:18,  6.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |  3000/ 3125 steps | loss 5.83619 | ppl  342.473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3125/3125 [05:43<00:00,  9.11it/s]\n",
            " 16%|█▌        | 502/3125 [00:55<04:10, 10.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   2 |   500/ 3125 steps | loss 5.53586 | ppl  253.626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 1002/3125 [01:51<03:43,  9.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   2 |  1000/ 3125 steps | loss 5.47166 | ppl  237.856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 1503/3125 [02:45<03:04,  8.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   2 |  1500/ 3125 steps | loss 5.44021 | ppl  230.490\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 2003/3125 [03:39<01:46, 10.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   2 |  2000/ 3125 steps | loss 5.40861 | ppl  223.321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 2502/3125 [04:35<01:05,  9.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   2 |  2500/ 3125 steps | loss 5.39006 | ppl  219.217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 3002/3125 [05:29<00:12, 10.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   2 |  3000/ 3125 steps | loss 5.34829 | ppl  210.249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3125/3125 [05:43<00:00,  9.11it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-BcBC6FSkMH3",
        "outputId": "7fb1ebfc-e680-4436-d29c-092c08c7a8c3"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt') \n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict']) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-11-28 23:57:50--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   170MB/s    in 0.5s    \n",
            "\n",
            "2021-11-28 23:57:50 (170 MB/s) - ‘pretrained_model_4layers.pt’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tBRRVsWqlIoQ",
        "outputId": "c505fff3-fb11-4735-adb1-9de11548c38d"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "--2021-11-28 23:57:55--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-11-28 23:57:56 (16.7 MB/s) - ‘sentencepiece.french.model’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TtLlV05pkQI3"
      },
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces]\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind = out[-1].argmax(-1)\n",
        "    return next_token_ind, out\n",
        "    \n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    # to be implemented\n",
        "    max_len -= len(sent.split(' '))\n",
        "    current_sentence, i = sent, 0\n",
        "    while i < max_len:\n",
        "        next_token_ind, _ = infer_next_token(current_sentence)\n",
        "        encoded_next_word = ind2token[next_token_ind.item()]\n",
        "        decoded_next_word = s.decode_pieces([encoded_next_word])\n",
        "        if decoded_next_word == \"<eos>\":\n",
        "            break\n",
        "        current_sentence += ' ' + decoded_next_word\n",
        "        i += 1\n",
        "    return current_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f83Nn5nSly4v",
        "outputId": "a3bc6c41-c3bb-4bfb-ed82-7a958841dce1"
      },
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Bonjour les gens qui ont été très accueillants et sympathiques .'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0K1BZsblmEmx",
        "outputId": "e9074e73-dd67-4f93-a887-222ba914162c"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-11-28 23:57:56--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm’\n",
            "\n",
            "train.review.spm    100%[===================>]   1.43M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-11-28 23:57:57 (21.0 MB/s) - ‘train.review.spm’ saved [1495960/1495960]\n",
            "\n",
            "--2021-11-28 23:57:57--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label’\n",
            "\n",
            "train.label         100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-28 23:57:57 (21.8 MB/s) - ‘train.label’ saved [3200/3200]\n",
            "\n",
            "--2021-11-28 23:57:57--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm’\n",
            "\n",
            "test.review.spm     100%[===================>]   1.78M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-11-28 23:57:58 (25.2 MB/s) - ‘test.review.spm’ saved [1864544/1864544]\n",
            "\n",
            "--2021-11-28 23:57:58--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label’\n",
            "\n",
            "test.label          100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-28 23:57:58 (51.2 MB/s) - ‘test.label’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_MLfvjiom2SL"
      },
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    #to be implemented\n",
        "    model.eval()\n",
        "    total_correct_predictions = total_length = 0\n",
        "    for idx, (input_data, target_data) in enumerate(data_loader):\n",
        "        src_mask = model.base.generate_square_subsequent_mask(\n",
        "            input_data.size(0)\n",
        "        ).to(device)\n",
        "        input_data = input_data.to(device)\n",
        "        output = model(input_data, src_mask)\n",
        "        output = output[-1]\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        max_prob_indices = output.argmax(-1)\n",
        "        target_data = target_data.to(device)\n",
        "        total_length += target_data.shape[0]\n",
        "        correct_predictions = torch.sum(target_data == max_prob_indices)\n",
        "        total_correct_predictions += correct_predictions.item()\n",
        "    return total_correct_predictions / total_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qzmx7T7xoa6v"
      },
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i-xclMCpnVpw",
        "outputId": "b2d10f0d-895b-4cfd-bd9a-5616a9f14948"
      },
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Training FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        print(f\"\\nCurrent accuracy: {acc}\\n\")\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=====Training FROM SCRATCH======\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:02<00:07, 20.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |    50/  200 steps | loss 0.74498 | ppl    2.106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 103/200 [00:05<00:05, 18.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   100/  200 steps | loss 0.71533 | ppl    2.045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 16.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   150/  200 steps | loss 0.74264 | ppl    2.101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.59\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 54/200 [00:02<00:06, 21.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   2 |    50/  200 steps | loss 0.68060 | ppl    1.975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 104/200 [00:05<00:05, 17.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   2 |   100/  200 steps | loss 0.59757 | ppl    1.818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 154/200 [00:08<00:02, 18.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   2 |   150/  200 steps | loss 0.56511 | ppl    1.760\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 18.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.69\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 52/200 [00:02<00:06, 21.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   3 |    50/  200 steps | loss 0.40774 | ppl    1.503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 102/200 [00:05<00:04, 19.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   3 |   100/  200 steps | loss 0.38612 | ppl    1.471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 18.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   3 |   150/  200 steps | loss 0.28999 | ppl    1.336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.708\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:02<00:08, 17.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   4 |    50/  200 steps | loss 0.14419 | ppl    1.155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 102/200 [00:05<00:04, 20.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   4 |   100/  200 steps | loss 0.15743 | ppl    1.170\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 16.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   4 |   150/  200 steps | loss 0.09104 | ppl    1.095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 18.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.7155\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 52/200 [00:02<00:09, 16.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   5 |    50/  200 steps | loss 0.01213 | ppl    1.012\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 104/200 [00:05<00:05, 18.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   5 |   100/  200 steps | loss 0.00603 | ppl    1.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 154/200 [00:08<00:02, 17.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   5 |   150/  200 steps | loss 0.03329 | ppl    1.034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.7205\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 52/200 [00:02<00:07, 20.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   6 |    50/  200 steps | loss 0.01948 | ppl    1.020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 104/200 [00:05<00:04, 19.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   6 |   100/  200 steps | loss 0.03609 | ppl    1.037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 16.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   6 |   150/  200 steps | loss 0.04249 | ppl    1.043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 17.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.718\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:02<00:07, 18.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   7 |    50/  200 steps | loss 0.00129 | ppl    1.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 104/200 [00:05<00:04, 19.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   7 |   100/  200 steps | loss 0.00047 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 19.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   7 |   150/  200 steps | loss 0.00087 | ppl    1.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.7205\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:02<00:08, 16.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   8 |    50/  200 steps | loss 0.00009 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 103/200 [00:05<00:05, 18.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   8 |   100/  200 steps | loss 0.00001 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 154/200 [00:08<00:02, 20.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   8 |   150/  200 steps | loss 0.00001 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 17.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.726\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 54/200 [00:03<00:08, 16.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   9 |    50/  200 steps | loss 0.00001 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 103/200 [00:05<00:05, 16.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   9 |   100/  200 steps | loss 0.00001 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 154/200 [00:08<00:02, 18.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   9 |   150/  200 steps | loss 0.00001 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 18.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.7205\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 54/200 [00:03<00:08, 17.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  10 |    50/  200 steps | loss 0.00001 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 103/200 [00:05<00:06, 15.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  10 |   100/  200 steps | loss 0.00001 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 16.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  10 |   150/  200 steps | loss 0.00001 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 18.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.7255\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:02<00:07, 20.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  11 |    50/  200 steps | loss 0.00000 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 103/200 [00:05<00:04, 20.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  11 |   100/  200 steps | loss 0.00001 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 155/200 [00:08<00:02, 20.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  11 |   150/  200 steps | loss 0.00001 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.723\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:02<00:08, 17.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  12 |    50/  200 steps | loss 0.00000 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 103/200 [00:05<00:05, 17.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  12 |   100/  200 steps | loss 0.00000 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 154/200 [00:08<00:02, 21.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  12 |   150/  200 steps | loss 0.00000 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.725\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 55/200 [00:02<00:06, 21.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  13 |    50/  200 steps | loss 0.00000 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 104/200 [00:05<00:04, 19.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  13 |   100/  200 steps | loss 0.00000 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 154/200 [00:08<00:02, 18.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  13 |   150/  200 steps | loss 0.00000 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.724\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:03<00:08, 18.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  14 |    50/  200 steps | loss 0.00000 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 104/200 [00:05<00:05, 18.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  14 |   100/  200 steps | loss 0.00000 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 152/200 [00:08<00:02, 20.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  14 |   150/  200 steps | loss 0.00000 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 18.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.727\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:03<00:08, 16.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  15 |    50/  200 steps | loss 0.00000 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 103/200 [00:05<00:05, 18.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  15 |   100/  200 steps | loss 0.00000 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 19.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  15 |   150/  200 steps | loss 0.00000 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 18.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.726\n",
            "\n",
            "=====PRETRAINED MODEL======\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 55/200 [00:03<00:07, 19.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |    50/  200 steps | loss 0.84677 | ppl    2.332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 103/200 [00:05<00:04, 19.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   100/  200 steps | loss 0.70701 | ppl    2.028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 19.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   150/  200 steps | loss 0.57858 | ppl    1.784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 18.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.76\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:02<00:08, 17.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   2 |    50/  200 steps | loss 0.46431 | ppl    1.591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 103/200 [00:05<00:05, 17.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   2 |   100/  200 steps | loss 0.51564 | ppl    1.675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 152/200 [00:08<00:02, 18.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   2 |   150/  200 steps | loss 0.42141 | ppl    1.524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.755\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:02<00:07, 18.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   3 |    50/  200 steps | loss 0.37158 | ppl    1.450\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 101/200 [00:05<00:04, 20.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   3 |   100/  200 steps | loss 0.43961 | ppl    1.552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 154/200 [00:08<00:02, 16.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   3 |   150/  200 steps | loss 0.33918 | ppl    1.404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 18.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.7815\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 52/200 [00:02<00:09, 15.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   4 |    50/  200 steps | loss 0.28326 | ppl    1.327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 104/200 [00:05<00:05, 19.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   4 |   100/  200 steps | loss 0.34810 | ppl    1.416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 154/200 [00:08<00:02, 18.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   4 |   150/  200 steps | loss 0.29760 | ppl    1.347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.789\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:02<00:08, 18.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   5 |    50/  200 steps | loss 0.21103 | ppl    1.235\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 103/200 [00:05<00:06, 15.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   5 |   100/  200 steps | loss 0.29938 | ppl    1.349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 152/200 [00:08<00:02, 20.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   5 |   150/  200 steps | loss 0.19754 | ppl    1.218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 18.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.79\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:02<00:06, 21.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   6 |    50/  200 steps | loss 0.12831 | ppl    1.137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 103/200 [00:05<00:05, 16.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   6 |   100/  200 steps | loss 0.15529 | ppl    1.168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 15.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   6 |   150/  200 steps | loss 0.23779 | ppl    1.268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 18.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.7845\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 55/200 [00:02<00:06, 21.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   7 |    50/  200 steps | loss 0.08437 | ppl    1.088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 103/200 [00:05<00:05, 17.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   7 |   100/  200 steps | loss 0.03506 | ppl    1.036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 16.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   7 |   150/  200 steps | loss 0.05257 | ppl    1.054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 18.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.7745\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 52/200 [00:02<00:06, 21.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   8 |    50/  200 steps | loss 0.00922 | ppl    1.009\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 102/200 [00:05<00:06, 16.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   8 |   100/  200 steps | loss 0.07087 | ppl    1.073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 17.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   8 |   150/  200 steps | loss 0.01787 | ppl    1.018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.772\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:02<00:07, 20.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   9 |    50/  200 steps | loss 0.03189 | ppl    1.032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 103/200 [00:05<00:05, 18.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   9 |   100/  200 steps | loss 0.01293 | ppl    1.013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 20.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   9 |   150/  200 steps | loss 0.02876 | ppl    1.029\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.7755\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 54/200 [00:03<00:07, 20.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  10 |    50/  200 steps | loss 0.05124 | ppl    1.053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 104/200 [00:05<00:04, 20.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  10 |   100/  200 steps | loss 0.00830 | ppl    1.008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 152/200 [00:08<00:02, 19.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  10 |   150/  200 steps | loss 0.00582 | ppl    1.006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:11<00:00, 18.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.7885\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 54/200 [00:03<00:09, 15.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  11 |    50/  200 steps | loss 0.00004 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 103/200 [00:05<00:05, 17.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  11 |   100/  200 steps | loss 0.02085 | ppl    1.021\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 18.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  11 |   150/  200 steps | loss 0.02870 | ppl    1.029\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.7665\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:02<00:06, 21.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  12 |    50/  200 steps | loss 0.04278 | ppl    1.044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 102/200 [00:05<00:05, 18.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  12 |   100/  200 steps | loss 0.00042 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 17.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  12 |   150/  200 steps | loss 0.00341 | ppl    1.003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.7795\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 53/200 [00:03<00:08, 17.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  13 |    50/  200 steps | loss 0.00400 | ppl    1.004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 102/200 [00:05<00:05, 18.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  13 |   100/  200 steps | loss 0.00034 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 152/200 [00:08<00:02, 18.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  13 |   150/  200 steps | loss 0.01062 | ppl    1.011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.7755\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 55/200 [00:03<00:07, 19.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  14 |    50/  200 steps | loss 0.00013 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 102/200 [00:05<00:04, 19.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  14 |   100/  200 steps | loss 0.00132 | ppl    1.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 153/200 [00:08<00:02, 17.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  14 |   150/  200 steps | loss 0.00048 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.7705\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 56/200 [00:03<00:06, 20.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  15 |    50/  200 steps | loss 0.00004 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 102/200 [00:05<00:04, 21.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  15 |   100/  200 steps | loss 0.00130 | ppl    1.001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 154/200 [00:08<00:02, 18.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch  15 |   150/  200 steps | loss 0.00000 | ppl    1.000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:10<00:00, 18.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Current accuracy: 0.783\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RCpBIdTHojm6",
        "outputId": "083bfd22-3726-4fc8-98ec-70a039962858"
      },
      "source": [
        "#Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(pretrained_valid_acc, 'c', label=\"Pretrained accuracy\")\n",
        "plt.plot(from_scratch_valid_acc, 'm', label=\"From scratch accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    }
  ]
}